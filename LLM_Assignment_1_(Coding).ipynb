{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DominiqueO/HS2023-Exercise08/blob/main/LLM_Assignment_1_(Coding).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm3aTSbtBKUl"
      },
      "source": [
        "# LLM Assignment 1: Representation Surgery (Coding)\n",
        "**IMPORTANT: MAKE A COPY OF THIS NOTEBOOK AND WORK IN THERE.**\n",
        "\n",
        "Welcome to the coding part of the Representation Surgery question in Assignment 1.\n",
        "The goal of this portion is to give you a deeper intuition for how representation surgery works and its strengths/limitations via hands-on implementations.\n",
        "\n",
        "It consists of 2 parts:\n",
        "1. Implementing linear concept erasure as described in the assignment, and applying it to a synthetic dataset.\n",
        "2. Applying concept erasure to erase the concept of \"gender\" from the BERT representations of a dataset of biographies.\n",
        "\n",
        "In this assignment, you'll have a series of tasks. For each task you will need to write some code and produce plots and/or accuracy results. You will need to export the notebook as a pdf and attach it to your submission. Please make sure all deliverables for each task (e.g., plots and accuracy results) are clearly visible, as we will be grading you on these outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7oLipZ4CkPv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rycolab/llm-representation-surgery.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhPM4fUTBKUn"
      },
      "outputs": [],
      "source": [
        "# These are all the imports you should need\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.cross_decomposition import CCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from typing import Tuple\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBQ0GSHeBKUo"
      },
      "source": [
        "## 0. Constructing a synthetic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPE3qJCsBKUp"
      },
      "source": [
        "First, we'll give you a synthetic dataset encoding a concept, i.e., the target labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5dRHC4_BKUp"
      },
      "outputs": [],
      "source": [
        "n, d, k = 2048, 128, 2\n",
        "X, Z = make_classification(\n",
        "    n_samples=n,\n",
        "    n_informative=k,\n",
        "    n_features=d,\n",
        "    n_classes=k,\n",
        "    random_state=1,\n",
        ")\n",
        "print(f\"Shape of X: {X.shape}, Shape of Z: {Z.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "270AUl79BKUq"
      },
      "source": [
        "What does this dataset look like? Visualizing 128-dimensional data is hard, so we'll reduce the dimensionality to 2 using CCA and plot the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia8aOBduBKUq"
      },
      "outputs": [],
      "source": [
        "def plot_cca(X, Z):\n",
        "    \"\"\"\n",
        "    Use Canonical Component Analysis to visualize the dataset X and label Z.\n",
        "    \"\"\"\n",
        "    Z_one_hot = np.zeros((len(Z), len(set(Z))))\n",
        "    Z_one_hot[np.arange(len(Z)), Z] = 1\n",
        "    cca = CCA(n_components=2)\n",
        "    X_cca = cca.fit_transform(X, y=Z_one_hot)[0]\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.scatter(X_cca[:, 0], X_cca[:, 1], c=Z, cmap='viridis')\n",
        "    plt.colorbar(label='Class')\n",
        "    plt.xlabel('First Principal Component')\n",
        "    plt.ylabel('Second Principal Component')\n",
        "    plt.title('CCA visualization of X')\n",
        "    plt.show()\n",
        "\n",
        "plot_cca(X, Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGY5gXClBKUq"
      },
      "source": [
        "As you can see, in these two components, the two concepts are fairly separable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp_OpLlrBKUq"
      },
      "source": [
        "### Task 0.1: Implement a logistic regression classifier predict the concept $Z$ from $X$.\n",
        "FOR THE SUBMISSION: Print the accuracy your classifier scores on the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2pKPTsJBKUq"
      },
      "outputs": [],
      "source": [
        "def logreg(X: np.ndarray, Z: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Train a logistic regression classifier to predict concept Z from X.\n",
        "\n",
        "    Args:\n",
        "        X - the data\n",
        "        Z - the concept/label\n",
        "\n",
        "    Return:\n",
        "        Accuracy in predicting Z from X.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "print(f\"Accuracy before erasure: {logreg(X, Z):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6EphtdRBKUq"
      },
      "source": [
        "## 1. Implementing linear concept erasure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUPHLR3BKUr"
      },
      "source": [
        "### Task 1.1: Validate that the resulting whitening and unwhitening matrices satisfy their definition and goals.\n",
        "That is, verify (a) $WW^{\\top} =I$ and (b) $cov(XW) = I$.\n",
        "\n",
        "FOR THE SUBMISSION: Include your plots showing the whitening matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhuDGvXuBKUr"
      },
      "outputs": [],
      "source": [
        "def compute_W(X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Compute the whitening and unwhitening matrix for the data using the ZCA whitening method\n",
        "    (see Appendix A of https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf for more details).\n",
        "    We give this to you as a numerically stable implementation.\n",
        "    \"\"\"\n",
        "    sigma = np.cov(X.T)\n",
        "\n",
        "    L, V = np.linalg.eigh(sigma)\n",
        "\n",
        "    # Assuming PSD; account for numerical error\n",
        "    L = L.clip(0.0)\n",
        "\n",
        "    # Threshold used by torch.linalg.pinv\n",
        "    mask = L > (L[-1] * sigma.shape[-1] * np.finfo(float).eps)\n",
        "\n",
        "    with np.errstate(divide='ignore'):\n",
        "      W = V * np.where(mask, 1/np.sqrt(L), 0.0) @ V.T\n",
        "      W_inv = V * np.where(mask, np.sqrt(L), 0.0) @ V.T\n",
        "\n",
        "    return W, W_inv\n",
        "\n",
        "def heatmap(arr, title):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(arr, cmap='viridis')\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "W, W_inv = compute_W(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTFRcciSBKUr"
      },
      "outputs": [],
      "source": [
        "def verify_W_W_inv(W, W_inv):\n",
        "    \"\"\"\n",
        "    Plot a heatmap of W @ W_inv to verify it satisfies the definition of whitening.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    pass\n",
        "\n",
        "verify_W_W_inv(W, W_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vttnf7lFBKUr"
      },
      "outputs": [],
      "source": [
        "def verify_cov_XW(X, W):\n",
        "    \"\"\"\n",
        "    Plot a heatmap of the covariance of XW to verify it satisfies the definition of whitening.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    pass\n",
        "\n",
        "verify_cov_XW(X, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8QfmD_gBKUr"
      },
      "source": [
        "### Task 1.2: Implement linear concept erasure\n",
        "Use the equations derived from the written part of the assignment.\n",
        "\n",
        "FOR THE WRITEUP: Include your plot and accuracy of the embeddings before erasure and after erasure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzIombmKBKUs"
      },
      "outputs": [],
      "source": [
        "def erase(X: np.ndarray, Z: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Implement linear concept erasure.\n",
        "\n",
        "    Args:\n",
        "        X - the data, shape (n, d)\n",
        "        Z - the concept/label, shape (n,)\n",
        "\n",
        "    Return:\n",
        "        The data with the concept erased. Shape (n, d).\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "erased_X = erase(X, Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwDVn8HTBKUs"
      },
      "source": [
        "Now, let's validate that the concept has been erased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cevZ1rkBKUs"
      },
      "outputs": [],
      "source": [
        "plot_cca(erased_X, Z)\n",
        "print(f\"Accuracy after erasure: {logreg(erased_X, Z)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Lmk8UCBKUt"
      },
      "source": [
        "## 2. Erasing gender bias\n",
        "In this portion, we'll apply the same method to a real dataset of word embeddings of biography data. Your goal is to (a) construct sentence embeddings and (b) erase the gender concept from these embeddings. Use the **`hard_text_untokenized`** column for your embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZevp-hiBKUt"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"llm-representation-surgery/data/biographies.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRCLpIWsBKUt"
      },
      "source": [
        "### Task 2.1: Compute embeddings and use the `erase` function defined above to erase the gender concept from the embeddings.\n",
        "\n",
        "FOR THE FOR THE SUBMISSION: Include:\n",
        "(a) CCA plot of the embeddings before erasure,\n",
        "(b) CCA plot of the embeddings after erasure,\n",
        "(c) logistic regression accuracy before erasure, and\n",
        "(d) logistic regression accuracy after erasure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shePLF5jBKUt"
      },
      "outputs": [],
      "source": [
        "def extract_gender_labels(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extract the gender labels from the dataframe.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "def compute_embeddings(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute the embeddings using a pretrained model for the \"hard_text_untokenized\" column of the given dataframe.\n",
        "    Feel free to experiment with different models; a good starting point is the classic BERT model, \"google-bert/bert-base-uncased\".\n",
        "    Also feel free to use any libraries which would be helpful, such as `transformers` or `sentence_transformers`.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "def erase_gender(embeddings: np.ndarray, gender_labels: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function should do 3 things:\n",
        "        1. Erase the gender concept from the embeddings and return these new embeddings.\n",
        "        2. Visualize the embeddings before erasure and print the accuracy before erasure.\n",
        "        3. Visualize the embeddings after erasure and print the accuracy after erasure.\n",
        "\n",
        "    Args:\n",
        "        embeddings: The embeddings to erase the gender concept from.\n",
        "        gender_labels: The gender labels for the embeddings.\n",
        "\n",
        "    Returns:\n",
        "        The embeddings with the gender concept erased.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "gender_labels = extract_gender_labels(df)\n",
        "embeddings = compute_embeddings(df)\n",
        "embeddings_erased = erase_gender(embeddings, gender_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xGT9kulBKUt"
      },
      "source": [
        "### Task 2.2: Verifying minimally-destructive edits.\n",
        "One key aspect of concept erasure is we want the edits to be *minimal*, i.e., they should not destroy other aspects of the representations. To test the degree to which the representation is preserved, use the profession as a proxy. Show that the profession information is preserved within the embeddings by computing the accuracy (a) before erasure and (b) after erasure.\n",
        "\n",
        "FOR THE SUBMISSION: Report the accuracy before and after erasure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI9YGr3UBKUt"
      },
      "outputs": [],
      "source": [
        "def visualize_profession(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Visualize the label distribution of professions, sorted from highest to lowest.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "visualize_profession(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBD11eB4BKUu"
      },
      "outputs": [],
      "source": [
        "def verify_profession_intact(embeddings: np.ndarray, embeddings_erased: np.ndarray, df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Verify the profession information is preserved within the embeddings.\n",
        "    \"\"\"\n",
        "    # TODO:\n",
        "    pass\n",
        "\n",
        "verify_profession_intact(embeddings, embeddings_erased, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoZGnQqMBKUu"
      },
      "source": [
        "### Task 2.3: Show that using a nonlinear classifier, you can recover the concept from the erased embeddings.\n",
        "\n",
        "While we've successfully removed gender from being *linearly encoded* in the embeddings, they can still be extracted using other models. Your goal is to extract the concept using some other model.\n",
        "\n",
        "FOR THE SUBMISSION: Report the accuracy before and after erasure."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nonlinear_classifier(embeddings: np.ndarray, gender_labels: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Train a nonlinear classifier on the embeddings to predict the gender labels and return the accuracy.\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    pass"
      ],
      "metadata": {
        "id": "JRDqGRqd4v61"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}